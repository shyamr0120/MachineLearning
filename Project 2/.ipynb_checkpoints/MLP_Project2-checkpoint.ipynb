{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "original = pd.read_csv('nba.csv', header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows: 1340\n",
      "Number of Columns: 21\n"
     ]
    }
   ],
   "source": [
    "total_rows=len(original.axes[0])\n",
    "total_cols=len(original.axes[1])\n",
    "print(\"Number of Rows: \"+str(total_rows))\n",
    "print(\"Number of Columns: \"+str(total_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name    False\n",
       "GP      False\n",
       "MIN     False\n",
       "PPT     False\n",
       "FGM     False\n",
       "FGA     False\n",
       "FG%     False\n",
       "3PM     False\n",
       "3PA     False\n",
       "3P%      True\n",
       "FTM     False\n",
       "FTA     False\n",
       "FT%     False\n",
       "OREB    False\n",
       "DREB    False\n",
       "REB     False\n",
       "AST     False\n",
       "STL     False\n",
       "BLK     False\n",
       "TOV     False\n",
       "TAR     False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checks to see which columns have missing values\n",
    "\n",
    "original.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "665\n",
      "22.4\n"
     ]
    }
   ],
   "source": [
    "# Replace the missing values with the median value of the column\n",
    "\n",
    "train2 = original.sort_values(by='3P%')\n",
    "nA = train2.iloc[:, 9].isnull().sum()\n",
    "vr = total_rows-nA\n",
    "if vr%2 != 0:\n",
    "    vr = vr + 1\n",
    "med = int(vr/2)\n",
    "medA = train2.iloc[med, 9]\n",
    "print(nA) # Number of null values in the column\n",
    "print(med) # Median index\n",
    "print(medA) # Median value\n",
    "original['3P%'] = original['3P%'].fillna(medA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary sklearn packages\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we remove the \"Name\" column, because the name of the player would not add any value in determining if the player\n",
    "# will last over 5 years\n",
    "\n",
    "target = original.iloc[:, -1]\n",
    "temp = original.iloc[:, 1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we create another dataframe where we remove/add other attributes and later compare its performace with the other\n",
    "# dataframe which only has the \"Name\" attribute removed\n",
    "\n",
    "temp2 = original.iloc[:, 1:20]\n",
    "temp2 = temp2.drop(['FGM', 'FGA', '3PM', '3PA', 'FTM', 'FTA', 'OREB', 'DREB'], axis = 1)\n",
    "\n",
    "temp2['P/MIN'] = temp2['GP']*temp2['PPT']/temp2['MIN']\n",
    "temp2 = temp2.drop(['GP', 'PPT'], axis = 1)\n",
    "\n",
    "temp2['REB/MIN'] = temp2['REB']/temp2['MIN']\n",
    "temp2['AST/MIN'] = temp2['AST']/temp2['MIN']\n",
    "temp2['STL/MIN'] = temp2['STL']/temp2['MIN']\n",
    "temp2['BLK/MIN'] = temp2['BLK']/temp2['MIN']\n",
    "temp2['TOV/MIN'] = temp2['TOV']/temp2['MIN']\n",
    "\n",
    "temp2.drop(['REB', 'AST', 'STL', 'BLK', 'TOV'], axis = 1)\n",
    "temp2 = temp2.drop(['REB', 'AST', 'STL', 'BLK', 'TOV'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Test Rows: 268\n",
      "Number of Test Columns: 19\n",
      "Number of Training Rows: 1072\n",
      "Number of Training Columns: 19\n"
     ]
    }
   ],
   "source": [
    "# We split the dataset into 80% training and 20% test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(temp, target, test_size=0.2, random_state = 42)\n",
    "\n",
    "test_rows=len(X_test.axes[0])\n",
    "test_cols=len(X_test.axes[1])\n",
    "print(\"Number of Test Rows: \"+str(test_rows))\n",
    "print(\"Number of Test Columns: \"+str(test_cols))\n",
    "\n",
    "train_rows=len(X_train.axes[0])\n",
    "train_cols=len(X_train.axes[1])\n",
    "print(\"Number of Training Rows: \"+str(train_rows))\n",
    "print(\"Number of Training Columns: \"+str(train_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom method that implements 10-fold cross validation\n",
    "\n",
    "def crossValidation(X, y, choice):\n",
    "    \n",
    "    length = int(train_rows/10)\n",
    "    \n",
    "    # The folds are set at these specific intervals to ensure a degree of sameness across the models.\n",
    "    # These folds are the validation set\n",
    "    \n",
    "    X1 = X.iloc[0:length]\n",
    "    X2 = X.iloc[length:length*2]\n",
    "    X3 = X.iloc[length*2:length*3]\n",
    "    X4 = X.iloc[length*3:length*4]\n",
    "    X5 = X.iloc[length*4:length*5]\n",
    "    X6 = X.iloc[length*5:length*6]\n",
    "    X7 = X.iloc[length*6:length*7]\n",
    "    X8 = X.iloc[length*7:length*8]\n",
    "    X9 = X.iloc[length*8:length*9]\n",
    "    X10 = X.iloc[length*9:train_rows]\n",
    "    \n",
    "    y1 = y.iloc[0:length]\n",
    "    y2 = y.iloc[length:length*2]\n",
    "    y3 = y.iloc[length*2:length*3]\n",
    "    y4 = y.iloc[length*3:length*4]\n",
    "    y5 = y.iloc[length*4:length*5]\n",
    "    y6 = y.iloc[length*5:length*6]\n",
    "    y7 = y.iloc[length*6:length*7]\n",
    "    y8 = y.iloc[length*7:length*8]\n",
    "    y9 = y.iloc[length*8:length*9]\n",
    "    y10 = y.iloc[length*9:train_rows]\n",
    "    \n",
    "    # These folds are the training sets for their respective validation sets\n",
    "    \n",
    "    fold2 = []\n",
    "    \n",
    "    for i in range(0, length):\n",
    "        fold2.append(i)\n",
    "        \n",
    "    for i in range(length*2, train_rows):\n",
    "        fold2.append(i)\n",
    "    \n",
    "    fold3 = []\n",
    "    \n",
    "    for i in range(0, length*2):\n",
    "        fold3.append(i)\n",
    "        \n",
    "    for i in range(length*3, train_rows):\n",
    "        fold3.append(i)\n",
    "    \n",
    "    fold4 = []\n",
    "    \n",
    "    for i in range(0, length*3):\n",
    "        fold4.append(i)\n",
    "        \n",
    "    for i in range(length*4, train_rows):\n",
    "        fold4.append(i)\n",
    "    \n",
    "    fold5 = []\n",
    "    \n",
    "    for i in range(0, length*4):\n",
    "        fold5.append(i)\n",
    "        \n",
    "    for i in range(length*5, train_rows):\n",
    "        fold5.append(i)\n",
    "    \n",
    "    fold6 = []\n",
    "    \n",
    "    for i in range(0, length*5):\n",
    "        fold6.append(i)\n",
    "        \n",
    "    for i in range(length*6, train_rows):\n",
    "        fold6.append(i)\n",
    "    \n",
    "    fold7 = []\n",
    "    \n",
    "    for i in range(0, length*6):\n",
    "        fold7.append(i)\n",
    "        \n",
    "    for i in range(length*7, train_rows):\n",
    "        fold7.append(i)\n",
    "    \n",
    "    fold8 = []\n",
    "    \n",
    "    for i in range(0, length*7):\n",
    "        fold8.append(i)\n",
    "        \n",
    "    for i in range(length*8, train_rows):\n",
    "        fold8.append(i)\n",
    "    \n",
    "    fold9 = []\n",
    "    \n",
    "    for i in range(0, length*8):\n",
    "        fold9.append(i)\n",
    "        \n",
    "    for i in range(length*9, train_rows):\n",
    "        fold9.append(i)\n",
    "    \n",
    "    X11 = X.iloc[length*2:train_rows]\n",
    "    X22 = X.iloc[fold2]\n",
    "    X33 = X.iloc[fold3]\n",
    "    X44 = X.iloc[fold4]\n",
    "    X55 = X.iloc[fold5]\n",
    "    X66 = X.iloc[fold6]\n",
    "    X77 = X.iloc[fold7]\n",
    "    X88 = X.iloc[fold8]\n",
    "    X99 = X.iloc[fold9]\n",
    "    X100 = X.iloc[0:length*9]\n",
    "    \n",
    "    y11 = y.iloc[length*2:train_rows]\n",
    "    y22 = y.iloc[fold2]\n",
    "    y33 = y.iloc[fold3]\n",
    "    y44 = y.iloc[fold4]\n",
    "    y55 = y.iloc[fold5]\n",
    "    y66 = y.iloc[fold6]\n",
    "    y77 = y.iloc[fold7]\n",
    "    y88 = y.iloc[fold8]\n",
    "    y99 = y.iloc[fold9]\n",
    "    y100 = y.iloc[0:length*9]\n",
    "    \n",
    "    # Choice of \"1\" implements 10-fold cross validation for K-Nearest Neighbors\n",
    "    \n",
    "    if(choice == 1):\n",
    "        great = 0.0\n",
    "        gm = 0\n",
    "        knn1 = KNeighborsClassifier(n_neighbors=5)\n",
    "        \n",
    "        knn1.fit(X11, y11)\n",
    "        \n",
    "        y_pred = knn1.predict(X1)\n",
    "        f1 = metrics.f1_score(y1, y_pred)\n",
    "        \n",
    "        if f1>great:\n",
    "            great = f1\n",
    "            gm = 1\n",
    "            \n",
    "        knn2 = KNeighborsClassifier(n_neighbors=5)\n",
    "        \n",
    "        knn2.fit(X22, y22)\n",
    "        \n",
    "        y_pred = knn2.predict(X2)\n",
    "        f2 = metrics.f1_score(y2, y_pred)\n",
    "        \n",
    "        if f2>great:\n",
    "            great = f2\n",
    "            gm = 2\n",
    "            \n",
    "        knn3 = KNeighborsClassifier(n_neighbors=5)\n",
    "        \n",
    "        knn3.fit(X33, y33)\n",
    "        \n",
    "        y_pred = knn3.predict(X3)\n",
    "        f3 = metrics.f1_score(y3, y_pred)\n",
    "        \n",
    "        if f3>great:\n",
    "            great = f3\n",
    "            gm = 3\n",
    "            \n",
    "        knn4 = KNeighborsClassifier(n_neighbors=5)\n",
    "        \n",
    "        knn4.fit(X44, y44)\n",
    "        \n",
    "        y_pred = knn1.predict(X4)\n",
    "        f4 = metrics.f1_score(y4, y_pred)\n",
    "        \n",
    "        if f4>great:\n",
    "            great = f4\n",
    "            gm = 4\n",
    "            \n",
    "        knn5 = KNeighborsClassifier(n_neighbors=5)\n",
    "        \n",
    "        knn5.fit(X55, y55)\n",
    "        \n",
    "        y_pred = knn5.predict(X5)\n",
    "        f5 = metrics.f1_score(y5, y_pred)\n",
    "        \n",
    "        if f5>great:\n",
    "            great = f5\n",
    "            gm = 5\n",
    "            \n",
    "        knn6 = KNeighborsClassifier(n_neighbors=5)\n",
    "        \n",
    "        knn6.fit(X66, y66)\n",
    "        \n",
    "        y_pred = knn6.predict(X6)\n",
    "        f6 = metrics.f1_score(y6, y_pred)\n",
    "        \n",
    "        if f6>great:\n",
    "            great = f6\n",
    "            gm = 6\n",
    "            \n",
    "        knn7 = KNeighborsClassifier(n_neighbors=5)\n",
    "        \n",
    "        knn7.fit(X77, y77)\n",
    "        \n",
    "        y_pred = knn7.predict(X7)\n",
    "        f7 = metrics.f1_score(y7, y_pred)\n",
    "        \n",
    "        if f7>great:\n",
    "            great = f7\n",
    "            gm = 7\n",
    "            \n",
    "        knn8 = KNeighborsClassifier(n_neighbors=5)\n",
    "        \n",
    "        knn8.fit(X88, y88)\n",
    "        \n",
    "        y_pred = knn8.predict(X8)\n",
    "        f8 = metrics.f1_score(y8, y_pred)\n",
    "        \n",
    "        if f8>great:\n",
    "            great = f8\n",
    "            gm = 8\n",
    "            \n",
    "        knn9 = KNeighborsClassifier(n_neighbors=5)\n",
    "        \n",
    "        knn9.fit(X99, y99)\n",
    "        \n",
    "        y_pred = knn9.predict(X9)\n",
    "        f9 = metrics.f1_score(y9, y_pred)\n",
    "        \n",
    "        if f9>great:\n",
    "            great = f9\n",
    "            gm = 9\n",
    "            \n",
    "        knn10 = KNeighborsClassifier(n_neighbors=5)\n",
    "        \n",
    "        knn10.fit(X100, y100)\n",
    "        \n",
    "        y_pred = knn10.predict(X10)\n",
    "        f10 = metrics.f1_score(y10, y_pred)\n",
    "        \n",
    "        if f10>great:\n",
    "            great = f10\n",
    "            gm = 10\n",
    "            \n",
    "            \n",
    "        if(gm==1):\n",
    "            return knn1\n",
    "        if(gm==2):\n",
    "            return knn2\n",
    "        if(gm==3):\n",
    "            return knn3\n",
    "        if(gm==4):\n",
    "            return knn4\n",
    "        if(gm==5):\n",
    "            return knn5\n",
    "        if(gm==6):\n",
    "            return knn6\n",
    "        if(gm==7):\n",
    "            return knn7\n",
    "        if(gm==8):\n",
    "            return knn8\n",
    "        if(gm==9):\n",
    "            return knn9\n",
    "        if(gm==10):\n",
    "            return knn10\n",
    "    \n",
    "    # Choice of \"2\" implements 10-fold cross validation for Random Forest\n",
    "    \n",
    "    if(choice == 2):\n",
    "        great = 0.0\n",
    "        gm = 0\n",
    "        knn1 = RandomForestClassifier(n_estimators=100)\n",
    "        \n",
    "        knn1.fit(X11, y11)\n",
    "        \n",
    "        y_pred = knn1.predict(X1)\n",
    "        f1 = metrics.f1_score(y1, y_pred)\n",
    "        \n",
    "        if f1>great:\n",
    "            great = f1\n",
    "            gm = 1\n",
    "            \n",
    "        knn2 = RandomForestClassifier(n_estimators=100)\n",
    "        \n",
    "        knn2.fit(X22, y22)\n",
    "        \n",
    "        y_pred = knn2.predict(X2)\n",
    "        f2 = metrics.f1_score(y2, y_pred)\n",
    "        \n",
    "        if f2>great:\n",
    "            great = f2\n",
    "            gm = 2\n",
    "            \n",
    "        knn3 = RandomForestClassifier(n_estimators=100)\n",
    "        \n",
    "        knn3.fit(X33, y33)\n",
    "        \n",
    "        y_pred = knn3.predict(X3)\n",
    "        f3 = metrics.f1_score(y3, y_pred)\n",
    "        \n",
    "        if f3>great:\n",
    "            great = f3\n",
    "            gm = 3\n",
    "            \n",
    "        knn4 = RandomForestClassifier(n_estimators=100)\n",
    "        \n",
    "        knn4.fit(X44, y44)\n",
    "        \n",
    "        y_pred = knn1.predict(X4)\n",
    "        f4 = metrics.f1_score(y4, y_pred)\n",
    "        \n",
    "        if f4>great:\n",
    "            great = f4\n",
    "            gm = 4\n",
    "            \n",
    "        knn5 = RandomForestClassifier(n_estimators=100)\n",
    "        \n",
    "        knn5.fit(X55, y55)\n",
    "        \n",
    "        y_pred = knn5.predict(X5)\n",
    "        f5 = metrics.f1_score(y5, y_pred)\n",
    "        \n",
    "        if f5>great:\n",
    "            great = f5\n",
    "            gm = 5\n",
    "            \n",
    "        knn6 = RandomForestClassifier(n_estimators=100)\n",
    "        \n",
    "        knn6.fit(X66, y66)\n",
    "        \n",
    "        y_pred = knn6.predict(X6)\n",
    "        f6 = metrics.f1_score(y6, y_pred)\n",
    "        \n",
    "        if f6>great:\n",
    "            great = f6\n",
    "            gm = 6\n",
    "            \n",
    "        knn7 = RandomForestClassifier(n_estimators=100)\n",
    "        \n",
    "        knn7.fit(X77, y77)\n",
    "        \n",
    "        y_pred = knn7.predict(X7)\n",
    "        f7 = metrics.f1_score(y7, y_pred)\n",
    "        \n",
    "        if f7>great:\n",
    "            great = f7\n",
    "            gm = 7\n",
    "            \n",
    "        knn8 = RandomForestClassifier(n_estimators=100)\n",
    "        \n",
    "        knn8.fit(X88, y88)\n",
    "        \n",
    "        y_pred = knn8.predict(X8)\n",
    "        f8 = metrics.f1_score(y8, y_pred)\n",
    "        \n",
    "        if f8>great:\n",
    "            great = f8\n",
    "            gm = 8\n",
    "            \n",
    "        knn9 = RandomForestClassifier(n_estimators=100)\n",
    "        \n",
    "        knn9.fit(X99, y99)\n",
    "        \n",
    "        y_pred = knn9.predict(X9)\n",
    "        f9 = metrics.f1_score(y9, y_pred)\n",
    "        \n",
    "        if f9>great:\n",
    "            great = f9\n",
    "            gm = 9\n",
    "            \n",
    "        knn10 = RandomForestClassifier(n_estimators=100)\n",
    "        \n",
    "        knn10.fit(X100, y100)\n",
    "        \n",
    "        y_pred = knn10.predict(X10)\n",
    "        f10 = metrics.f1_score(y10, y_pred)\n",
    "        \n",
    "        if f10>great:\n",
    "            great = f10\n",
    "            gm = 10\n",
    "            \n",
    "            \n",
    "        if(gm==1):\n",
    "            return knn1\n",
    "        if(gm==2):\n",
    "            return knn2\n",
    "        if(gm==3):\n",
    "            return knn3\n",
    "        if(gm==4):\n",
    "            return knn4\n",
    "        if(gm==5):\n",
    "            return knn5\n",
    "        if(gm==6):\n",
    "            return knn6\n",
    "        if(gm==7):\n",
    "            return knn7\n",
    "        if(gm==8):\n",
    "            return knn8\n",
    "        if(gm==9):\n",
    "            return knn9\n",
    "        if(gm==10):\n",
    "            return knn10\n",
    "        \n",
    "    # Choice of \"3\" implements 10-fold cross validation for Logistic Regression\n",
    "    \n",
    "    if(choice == 3):\n",
    "        great = 0.0\n",
    "        gm = 0\n",
    "        knn1 = LogisticRegression(max_iter=20000)\n",
    "        \n",
    "        knn1.fit(X11, y11)\n",
    "        \n",
    "        y_pred = knn1.predict(X1)\n",
    "        f1 = metrics.f1_score(y1, y_pred)\n",
    "        \n",
    "        if f1>great:\n",
    "            great = f1\n",
    "            gm = 1\n",
    "            \n",
    "        knn2 = LogisticRegression(max_iter=20000)\n",
    "        \n",
    "        knn2.fit(X22, y22)\n",
    "        \n",
    "        y_pred = knn2.predict(X2)\n",
    "        f2 = metrics.f1_score(y2, y_pred)\n",
    "        \n",
    "        if f2>great:\n",
    "            great = f2\n",
    "            gm = 2\n",
    "            \n",
    "        knn3 = LogisticRegression(max_iter=20000)\n",
    "        \n",
    "        knn3.fit(X33, y33)\n",
    "        \n",
    "        y_pred = knn3.predict(X3)\n",
    "        f3 = metrics.f1_score(y3, y_pred)\n",
    "        \n",
    "        if f3>great:\n",
    "            great = f3\n",
    "            gm = 3\n",
    "            \n",
    "        knn4 = LogisticRegression(max_iter=20000)\n",
    "        \n",
    "        knn4.fit(X44, y44)\n",
    "        \n",
    "        y_pred = knn1.predict(X4)\n",
    "        f4 = metrics.f1_score(y4, y_pred)\n",
    "        \n",
    "        if f4>great:\n",
    "            great = f4\n",
    "            gm = 4\n",
    "            \n",
    "        knn5 = LogisticRegression(max_iter=20000)\n",
    "        \n",
    "        knn5.fit(X55, y55)\n",
    "        \n",
    "        y_pred = knn5.predict(X5)\n",
    "        f5 = metrics.f1_score(y5, y_pred)\n",
    "        \n",
    "        if f5>great:\n",
    "            great = f5\n",
    "            gm = 5\n",
    "            \n",
    "        knn6 = LogisticRegression(max_iter=20000)\n",
    "        \n",
    "        knn6.fit(X66, y66)\n",
    "        \n",
    "        y_pred = knn6.predict(X6)\n",
    "        f6 = metrics.f1_score(y6, y_pred)\n",
    "        \n",
    "        if f6>great:\n",
    "            great = f6\n",
    "            gm = 6\n",
    "            \n",
    "        knn7 = LogisticRegression(max_iter=20000)\n",
    "        \n",
    "        knn7.fit(X77, y77)\n",
    "        \n",
    "        y_pred = knn7.predict(X7)\n",
    "        f7 = metrics.f1_score(y7, y_pred)\n",
    "        \n",
    "        if f7>great:\n",
    "            great = f7\n",
    "            gm = 7\n",
    "            \n",
    "        knn8 = LogisticRegression(max_iter=20000)\n",
    "        \n",
    "        knn8.fit(X88, y88)\n",
    "        \n",
    "        y_pred = knn8.predict(X8)\n",
    "        f8 = metrics.f1_score(y8, y_pred)\n",
    "        \n",
    "        if f8>great:\n",
    "            great = f8\n",
    "            gm = 8\n",
    "            \n",
    "        knn9 = LogisticRegression(max_iter=20000)\n",
    "        \n",
    "        knn9.fit(X99, y99)\n",
    "        \n",
    "        y_pred = knn9.predict(X9)\n",
    "        f9 = metrics.f1_score(y9, y_pred)\n",
    "        \n",
    "        if f9>great:\n",
    "            great = f9\n",
    "            gm = 9\n",
    "            \n",
    "        knn10 = LogisticRegression(max_iter=20000)\n",
    "        \n",
    "        knn10.fit(X100, y100)\n",
    "        \n",
    "        y_pred = knn10.predict(X10)\n",
    "        f10 = metrics.f1_score(y10, y_pred)\n",
    "        \n",
    "        if f10>great:\n",
    "            great = f10\n",
    "            gm = 10\n",
    "            \n",
    "            \n",
    "        if(gm==1):\n",
    "            return knn1\n",
    "        if(gm==2):\n",
    "            return knn2\n",
    "        if(gm==3):\n",
    "            return knn3\n",
    "        if(gm==4):\n",
    "            return knn4\n",
    "        if(gm==5):\n",
    "            return knn5\n",
    "        if(gm==6):\n",
    "            return knn6\n",
    "        if(gm==7):\n",
    "            return knn7\n",
    "        if(gm==8):\n",
    "            return knn8\n",
    "        if(gm==9):\n",
    "            return knn9\n",
    "        if(gm==10):\n",
    "            return knn10\n",
    "        \n",
    "    # Choice of \"4\" implements 10-fold cross validation for MLP Classifier\n",
    "    \n",
    "    if(choice == 4):\n",
    "        great = 0.0\n",
    "        gm = 0\n",
    "        knn1 = MLPClassifier(max_iter=20000, early_stopping = True)\n",
    "        \n",
    "        knn1.fit(X11, y11)\n",
    "        \n",
    "        y_pred = knn1.predict(X1)\n",
    "        f1 = metrics.f1_score(y1, y_pred)\n",
    "        \n",
    "        if f1>great:\n",
    "            great = f1\n",
    "            gm = 1\n",
    "            \n",
    "        knn2 = MLPClassifier(max_iter=20000, early_stopping = True)\n",
    "        \n",
    "        knn2.fit(X22, y22)\n",
    "        \n",
    "        y_pred = knn2.predict(X2)\n",
    "        f2 = metrics.f1_score(y2, y_pred)\n",
    "        \n",
    "        if f2>great:\n",
    "            great = f2\n",
    "            gm = 2\n",
    "            \n",
    "        knn3 = MLPClassifier(max_iter=20000, early_stopping = True)\n",
    "        \n",
    "        knn3.fit(X33, y33)\n",
    "        \n",
    "        y_pred = knn3.predict(X3)\n",
    "        f3 = metrics.f1_score(y3, y_pred)\n",
    "        \n",
    "        if f3>great:\n",
    "            great = f3\n",
    "            gm = 3\n",
    "            \n",
    "        knn4 = MLPClassifier(max_iter=20000, early_stopping = True)\n",
    "        \n",
    "        knn4.fit(X44, y44)\n",
    "        \n",
    "        y_pred = knn1.predict(X4)\n",
    "        f4 = metrics.f1_score(y4, y_pred)\n",
    "        \n",
    "        if f4>great:\n",
    "            great = f4\n",
    "            gm = 4\n",
    "            \n",
    "        knn5 = MLPClassifier(max_iter=20000, early_stopping = True)\n",
    "        \n",
    "        knn5.fit(X55, y55)\n",
    "        \n",
    "        y_pred = knn5.predict(X5)\n",
    "        f5 = metrics.f1_score(y5, y_pred)\n",
    "        \n",
    "        if f5>great:\n",
    "            great = f5\n",
    "            gm = 5\n",
    "            \n",
    "        knn6 = MLPClassifier(max_iter=20000, early_stopping = True)\n",
    "        \n",
    "        knn6.fit(X66, y66)\n",
    "        \n",
    "        y_pred = knn6.predict(X6)\n",
    "        f6 = metrics.f1_score(y6, y_pred)\n",
    "        \n",
    "        if f6>great:\n",
    "            great = f6\n",
    "            gm = 6\n",
    "            \n",
    "        knn7 = MLPClassifier(max_iter=20000, early_stopping = True)\n",
    "        \n",
    "        knn7.fit(X77, y77)\n",
    "        \n",
    "        y_pred = knn7.predict(X7)\n",
    "        f7 = metrics.f1_score(y7, y_pred)\n",
    "        \n",
    "        if f7>great:\n",
    "            great = f7\n",
    "            gm = 7\n",
    "            \n",
    "        knn8 = MLPClassifier(max_iter=20000, early_stopping = True)\n",
    "        \n",
    "        knn8.fit(X88, y88)\n",
    "        \n",
    "        y_pred = knn8.predict(X8)\n",
    "        f8 = metrics.f1_score(y8, y_pred)\n",
    "        \n",
    "        if f8>great:\n",
    "            great = f8\n",
    "            gm = 8\n",
    "            \n",
    "        knn9 = MLPClassifier(max_iter=20000, early_stopping = True)\n",
    "        \n",
    "        knn9.fit(X99, y99)\n",
    "        \n",
    "        y_pred = knn9.predict(X9)\n",
    "        f9 = metrics.f1_score(y9, y_pred)\n",
    "        \n",
    "        if f9>great:\n",
    "            great = f9\n",
    "            gm = 9\n",
    "            \n",
    "        knn10 = MLPClassifier(max_iter=20000, early_stopping = True)\n",
    "        \n",
    "        knn10.fit(X100, y100)\n",
    "        \n",
    "        y_pred = knn10.predict(X10)\n",
    "        f10 = metrics.f1_score(y10, y_pred)\n",
    "        \n",
    "        if f10>great:\n",
    "            great = f10\n",
    "            gm = 10\n",
    "            \n",
    "            \n",
    "        if(gm==1):\n",
    "            return knn1\n",
    "        if(gm==2):\n",
    "            return knn2\n",
    "        if(gm==3):\n",
    "            return knn3\n",
    "        if(gm==4):\n",
    "            return knn4\n",
    "        if(gm==5):\n",
    "            return knn5\n",
    "        if(gm==6):\n",
    "            return knn6\n",
    "        if(gm==7):\n",
    "            return knn7\n",
    "        if(gm==8):\n",
    "            return knn8\n",
    "        if(gm==9):\n",
    "            return knn9\n",
    "        if(gm==10):\n",
    "            return knn10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1 Scores for the Data Frame without any Removed/Added Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for K-Nearest Neighbors using Custom Cross Validation Method: 0.7374301675977653\n",
      "F1 Score for K-Nearest Neighbors using GridSearchCV with Default Scoring Parameter: 0.7374301675977653\n",
      "\n",
      "F1 Score for Random Forests using Custom Cross Validation Method: 0.7696629213483145\n",
      "F1 Score for Random Forests using GridSearchCV with Default Scoring Parameter: 0.7722222222222224\n",
      "\n",
      "F1 Score for Logistic Regression using Custom Cross Validation Method: 0.8111111111111111\n",
      "F1 Score for Logistic Regression using GridSearchCV with Default Scoring Parameter: 0.8111111111111111\n",
      "\n",
      "F1 Score for Artificial Neural Network using Custom Cross Validation Method: 0.7762803234501346\n",
      "F1 Score for Artificial Neural Network using GridSearchCV with Default Scoring Parameter: 0.7745098039215687\n",
      "Wall time: 12.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# This cell calls the custom cross validation method and GridSearchCV to run the models and get an F1 score\n",
    "# The dataset without removed/added attributes is used here\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(temp, target, test_size=0.2, random_state = 42) # 80% training and 20% test\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "\n",
    "# Calls custom cross validation\n",
    "knn = crossValidation(X_train, y_train, 1)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"F1 Score for K-Nearest Neighbors using Custom Cross Validation Method:\",metrics.f1_score(y_test, y_pred))\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Uses the cross validation available in Grid Search\n",
    "# Grid Search is run with the default parameters\n",
    "gs_random = GridSearchCV(estimator = knn, param_grid = {}, scoring = 'f1', cv= 10)\n",
    "gs_random.fit(X_train, y_train)\n",
    "knn_best_model = gs_random.best_estimator_\n",
    "\n",
    "y_pred = knn_best_model.predict(X_test)\n",
    "print(\"F1 Score for K-Nearest Neighbors using GridSearchCV with Default Scoring Parameter:\",metrics.f1_score(y_test, y_pred))\n",
    "\n",
    "# Random Forests\n",
    "\n",
    "clf = crossValidation(X_train, y_train, 2)\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "print(\"\\nF1 Score for Random Forests using Custom Cross Validation Method:\",metrics.f1_score(y_test, y_pred))\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "gs_random = GridSearchCV(estimator = clf, param_grid = {}, scoring = 'f1', cv= 10)\n",
    "gs_random.fit(X_train, y_train)\n",
    "clf_best_model = gs_random.best_estimator_\n",
    "\n",
    "y_pred = clf_best_model.predict(X_test)\n",
    "print(\"F1 Score for Random Forests using GridSearchCV with Default Scoring Parameter:\",metrics.f1_score(y_test, y_pred))\n",
    "\n",
    "# Logistic Regression\n",
    "\n",
    "logreg = crossValidation(X_train, y_train, 3)\n",
    "\n",
    "logreg.fit(X_train,y_train)\n",
    "\n",
    "y_pred=logreg.predict(X_test)\n",
    "print(\"\\nF1 Score for Logistic Regression using Custom Cross Validation Method:\",metrics.f1_score(y_test, y_pred))\n",
    "\n",
    "logreg = LogisticRegression(max_iter=20000)\n",
    "\n",
    "gs_random = GridSearchCV(estimator = logreg, param_grid = {}, scoring = 'f1', cv= 10)\n",
    "gs_random.fit(X_train, y_train)\n",
    "logreg_best_model = gs_random.best_estimator_\n",
    "\n",
    "y_pred = logreg_best_model.predict(X_test)\n",
    "print(\"F1 Score for Logistic Regression using GridSearchCV with Default Scoring Parameter:\",metrics.f1_score(y_test, y_pred))\n",
    "\n",
    "# Artificial Neural Networks\n",
    "\n",
    "mlpc = crossValidation(X_train, y_train, 4)\n",
    "\n",
    "mlpc.fit(X_train,y_train)\n",
    "\n",
    "y_pred=mlpc.predict(X_test)\n",
    "print(\"\\nF1 Score for Artificial Neural Network using Custom Cross Validation Method:\",metrics.f1_score(y_test, y_pred))\n",
    "\n",
    "mlpc = MLPClassifier(max_iter=20000, early_stopping = True)\n",
    "\n",
    "gs_random = GridSearchCV(estimator = mlpc, param_grid = {}, scoring = 'f1', cv= 10)\n",
    "gs_random.fit(X_train, y_train)\n",
    "mlpc_best_model = gs_random.best_estimator_\n",
    "\n",
    "y_pred = mlpc_best_model.predict(X_test)\n",
    "print(\"F1 Score for Artificial Neural Network using GridSearchCV with Default Scoring Parameter:\",metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1 Scores for the Data Frame with Removed/Added Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for K-Nearest Neighbors using Custom Cross Validation Method: 0.7811634349030471\n",
      "F1 Score for K-Nearest Neighbors using GridSearchCV with Default Scoring Parameter: 0.7811634349030471\n",
      "\n",
      "F1 Score for Random Forests using Custom Cross Validation Method: 0.8089887640449438\n",
      "F1 Score for Random Forests using GridSearchCV with Default Scoring Parameter: 0.7932960893854748\n",
      "\n",
      "F1 Score for Logistic Regression using Custom Cross Validation Method: 0.7978142076502731\n",
      "F1 Score for Logistic Regression using GridSearchCV with Default Scoring Parameter: 0.7978142076502731\n",
      "\n",
      "F1 Score for Artificial Neural Network using Custom Cross Validation Method: 0.7643678160919539\n",
      "F1 Score for Artificial Neural Network using GridSearchCV with Default Scoring Parameter: 0.7706422018348623\n",
      "Wall time: 8.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# This cell calls the custom cross validation method and GridSearchCV to run the models and get an F1 score\n",
    "# The dataset with removed/added attributes is used here\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(temp2, target, test_size=0.2, random_state = 42) # 80% training and 20% test\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "\n",
    "knn = crossValidation(X_train, y_train, 1)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"F1 Score for K-Nearest Neighbors using Custom Cross Validation Method:\",metrics.f1_score(y_test, y_pred))\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "gs_random = GridSearchCV(estimator = knn, param_grid = {}, scoring = 'f1', cv= 10)\n",
    "gs_random.fit(X_train, y_train)\n",
    "knn_best_model = gs_random.best_estimator_\n",
    "\n",
    "y_pred = knn_best_model.predict(X_test)\n",
    "print(\"F1 Score for K-Nearest Neighbors using GridSearchCV with Default Scoring Parameter:\",metrics.f1_score(y_test, y_pred))\n",
    "\n",
    "# Random Forests\n",
    "\n",
    "clf = crossValidation(X_train, y_train, 2)\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "print(\"\\nF1 Score for Random Forests using Custom Cross Validation Method:\",metrics.f1_score(y_test, y_pred))\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "gs_random = GridSearchCV(estimator = clf, param_grid = {}, scoring = 'f1', cv= 10)\n",
    "gs_random.fit(X_train, y_train)\n",
    "clf_best_model = gs_random.best_estimator_\n",
    "\n",
    "y_pred = clf_best_model.predict(X_test)\n",
    "print(\"F1 Score for Random Forests using GridSearchCV with Default Scoring Parameter:\",metrics.f1_score(y_test, y_pred))\n",
    "\n",
    "# Logistic Regression\n",
    "\n",
    "logreg = crossValidation(X_train, y_train, 3)\n",
    "\n",
    "logreg.fit(X_train,y_train)\n",
    "\n",
    "y_pred=logreg.predict(X_test)\n",
    "print(\"\\nF1 Score for Logistic Regression using Custom Cross Validation Method:\",metrics.f1_score(y_test, y_pred))\n",
    "\n",
    "logreg = LogisticRegression(max_iter=20000)\n",
    "\n",
    "gs_random = GridSearchCV(estimator = logreg, param_grid = {}, scoring = 'f1', cv= 10)\n",
    "gs_random.fit(X_train, y_train)\n",
    "logreg_best_model = gs_random.best_estimator_\n",
    "\n",
    "y_pred = logreg_best_model.predict(X_test)\n",
    "print(\"F1 Score for Logistic Regression using GridSearchCV with Default Scoring Parameter:\",metrics.f1_score(y_test, y_pred))\n",
    "\n",
    "# Artificial Neural Networks\n",
    "\n",
    "mlpc = crossValidation(X_train, y_train, 4)\n",
    "\n",
    "mlpc.fit(X_train,y_train)\n",
    "\n",
    "y_pred=mlpc.predict(X_test)\n",
    "print(\"\\nF1 Score for Artificial Neural Network using Custom Cross Validation Method:\",metrics.f1_score(y_test, y_pred))\n",
    "\n",
    "mlpc = MLPClassifier(max_iter=20000, early_stopping = True)\n",
    "\n",
    "gs_random = GridSearchCV(estimator = mlpc, param_grid = {}, scoring = 'f1', cv= 10)\n",
    "gs_random.fit(X_train, y_train)\n",
    "mlpc_best_model = gs_random.best_estimator_\n",
    "\n",
    "y_pred = mlpc_best_model.predict(X_test)\n",
    "print(\"F1 Score for Artificial Neural Network using GridSearchCV with Default Scoring Parameter:\",metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1 Scores with Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Scores after Normalization\n",
      "\n",
      "F1 Score for K-Nearest Neighbors using GridSearchCV with Default Scoring Parameter: 0.777142857142857\n",
      "F1 Score for Random Forests using GridSearchCV with Default Scoring Parameter: 0.788888888888889\n",
      "F1 Score for Logistic Regression using GridSearchCV with Default Scoring Parameter: 0.78125\n",
      "F1 Score for Artificial Neural Network using GridSearchCV with Default Scoring Parameter: 0.7734553775743707\n",
      "Wall time: 3.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# This cell runs the models after the data has been normalized\n",
    "# GridSearchCV with default parameters is used for cross validation\n",
    "\n",
    "temp = temp2 # The dataframe with the best average F1 score across models was picked. In this case, it was the dataframe with\n",
    "# the attributes removed/added\n",
    "\n",
    "ntemp = preprocessing.normalize(temp) # Performs normalization on the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(ntemp, target, test_size=0.2, random_state = 42) # 80% training and 20% test\n",
    "\n",
    "print(\"F1 Scores after Normalization\\n\")\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "gs_random = GridSearchCV(estimator = knn, param_grid = {}, scoring = 'f1', cv= 10)\n",
    "gs_random.fit(X_train, y_train)\n",
    "knn_best_model = gs_random.best_estimator_\n",
    "\n",
    "y_pred = knn_best_model.predict(X_test)\n",
    "print(\"F1 Score for K-Nearest Neighbors using GridSearchCV with Default Scoring Parameter:\",metrics.f1_score(y_test, y_pred))\n",
    "\n",
    "# Random Forests\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "gs_random = GridSearchCV(estimator = clf, param_grid = {}, scoring = 'f1', cv= 10)\n",
    "gs_random.fit(X_train, y_train)\n",
    "clf_best_model = gs_random.best_estimator_\n",
    "\n",
    "y_pred = clf_best_model.predict(X_test)\n",
    "print(\"F1 Score for Random Forests using GridSearchCV with Default Scoring Parameter:\",metrics.f1_score(y_test, y_pred))\n",
    "\n",
    "# Logistic Regression\n",
    "\n",
    "logreg = LogisticRegression(max_iter=20000)\n",
    "\n",
    "gs_random = GridSearchCV(estimator = logreg, param_grid = {}, scoring = 'f1', cv= 10)\n",
    "gs_random.fit(X_train, y_train)\n",
    "logreg_best_model = gs_random.best_estimator_\n",
    "\n",
    "y_pred = logreg_best_model.predict(X_test)\n",
    "print(\"F1 Score for Logistic Regression using GridSearchCV with Default Scoring Parameter:\",metrics.f1_score(y_test, y_pred))\n",
    "\n",
    "# Artificial Neural Networks\n",
    "\n",
    "mlpc = MLPClassifier(max_iter=20000, early_stopping = True)\n",
    "\n",
    "gs_random = GridSearchCV(estimator = mlpc, param_grid = {}, scoring = 'f1', cv= 10)\n",
    "gs_random.fit(X_train, y_train)\n",
    "mlpc_best_model = gs_random.best_estimator_\n",
    "\n",
    "y_pred = mlpc_best_model.predict(X_test)\n",
    "print(\"F1 Score for Artificial Neural Network using GridSearchCV with Default Scoring Parameter:\",metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1 Scores with Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Scores after Standardization\n",
      "\n",
      "F1 Score for K-Nearest Neighbors using GridSearchCV with Default Scoring Parameter: 0.7768595041322313\n",
      "F1 Score for Random Forests using GridSearchCV with Default Scoring Parameter: 0.7899159663865546\n",
      "F1 Score for Logistic Regression using GridSearchCV with Default Scoring Parameter: 0.8033707865168538\n",
      "F1 Score for Artificial Neural Network using GridSearchCV with Default Scoring Parameter: 0.7955801104972376\n",
      "Wall time: 4.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# This cell runs the models after the data has been standardized\n",
    "# GridSearchCV with default parameters is used for cross validation\n",
    "\n",
    "temp = temp2\n",
    "stemp = preprocessing.scale(temp) # Performs standardization on the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(stemp, target, test_size=0.2, random_state = 42) # 80% training and 20% test\n",
    "\n",
    "print(\"F1 Scores after Standardization\\n\")\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "gs_random = GridSearchCV(estimator = knn, param_grid = {}, scoring = 'f1', cv= 10)\n",
    "gs_random.fit(X_train, y_train)\n",
    "knn_best_model = gs_random.best_estimator_\n",
    "\n",
    "y_pred = knn_best_model.predict(X_test)\n",
    "print(\"F1 Score for K-Nearest Neighbors using GridSearchCV with Default Scoring Parameter:\",metrics.f1_score(y_test, y_pred))\n",
    "\n",
    "# Random Forests\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "gs_random = GridSearchCV(estimator = clf, param_grid = {}, scoring = 'f1', cv= 10)\n",
    "gs_random.fit(X_train, y_train)\n",
    "clf_best_model = gs_random.best_estimator_\n",
    "\n",
    "y_pred = clf_best_model.predict(X_test)\n",
    "print(\"F1 Score for Random Forests using GridSearchCV with Default Scoring Parameter:\",metrics.f1_score(y_test, y_pred))\n",
    "\n",
    "# Logistic Regression\n",
    "\n",
    "logreg = LogisticRegression(max_iter=20000)\n",
    "\n",
    "gs_random = GridSearchCV(estimator = logreg, param_grid = {}, scoring = 'f1', cv= 10)\n",
    "gs_random.fit(X_train, y_train)\n",
    "logreg_best_model = gs_random.best_estimator_\n",
    "\n",
    "y_pred = logreg_best_model.predict(X_test)\n",
    "print(\"F1 Score for Logistic Regression using GridSearchCV with Default Scoring Parameter:\",metrics.f1_score(y_test, y_pred))\n",
    "\n",
    "# Artificial Neural Networks\n",
    "\n",
    "mlpc = MLPClassifier(max_iter=20000, early_stopping = True)\n",
    "\n",
    "gs_random = GridSearchCV(estimator = mlpc, param_grid = {}, scoring = 'f1', cv= 10)\n",
    "gs_random.fit(X_train, y_train)\n",
    "mlpc_best_model = gs_random.best_estimator_\n",
    "\n",
    "y_pred = mlpc_best_model.predict(X_test)\n",
    "print(\"F1 Score for Artificial Neural Network using GridSearchCV with Default Scoring Parameter:\",metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1 Scores for Logistic Regression Using the Various Regularization Penalties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without Data Manipulation\n",
      "\n",
      "F1 Score for Logistic Regression with no penaltly using GridSearchCV with Default Scoring Parameter: 0.8032786885245901\n",
      "F1 Score for Logistic Regression with l1 penaltly using GridSearchCV with Default Scoring Parameter: 0.7989130434782609\n",
      "F1 Score for Logistic Regression with l2 penaltly using GridSearchCV with Default Scoring Parameter: 0.7956403269754767\n",
      "F1 Score for Logistic Regression with elasticnet penaltly using GridSearchCV with Default Scoring Parameter: 0.8010899182561307\n",
      "\n",
      "With Normalization\n",
      "\n",
      "F1 Score for Logistic Regression with no penaltly using GridSearchCV with Default Scoring Parameter: 0.782608695652174\n",
      "F1 Score for Logistic Regression with l1 penaltly using GridSearchCV with Default Scoring Parameter: 0.7795698924731184\n",
      "F1 Score for Logistic Regression with l2 penaltly using GridSearchCV with Default Scoring Parameter: 0.78125\n",
      "F1 Score for Logistic Regression with elasticnet penaltly using GridSearchCV with Default Scoring Parameter: 0.7704485488126649\n",
      "\n",
      "With Standardization\n",
      "\n",
      "F1 Score for Logistic Regression with no penaltly using GridSearchCV with Default Scoring Parameter: 0.8033707865168538\n",
      "F1 Score for Logistic Regression with l1 penaltly using GridSearchCV with Default Scoring Parameter: 0.8033707865168538\n",
      "F1 Score for Logistic Regression with l2 penaltly using GridSearchCV with Default Scoring Parameter: 0.8033707865168538\n",
      "F1 Score for Logistic Regression with elasticnet penaltly using GridSearchCV with Default Scoring Parameter: 0.8033707865168538\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# This cell runs the various regularization penalties on the Logistic Regression model\n",
    "# It is run for when the data has not been scaled, has been normalized, and for when it has been standardized\n",
    "\n",
    "temp = temp2\n",
    "ntemp = preprocessing.normalize(temp)\n",
    "stemp = preprocessing.scale(temp)\n",
    "print(\"Without Data Manipulation\\n\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(temp, target, test_size=0.2, random_state = 42)\n",
    "\n",
    "# No penalty\n",
    "\n",
    "logreg = LogisticRegression(max_iter=20000)\n",
    "\n",
    "gs_random = GridSearchCV(estimator = logreg, param_grid = {'penalty': ['none'], 'solver': ['saga']}, scoring = 'f1', cv= 10)\n",
    "# The 'saga' solver is used here because it is the only one which supports all the regularization penalties\n",
    "\n",
    "gs_random.fit(X_train, y_train)\n",
    "logreg_best_model = gs_random.best_estimator_\n",
    "\n",
    "y_pred = logreg_best_model.predict(X_test)\n",
    "print(\"F1 Score for Logistic Regression with no penaltly using GridSearchCV with Default Scoring Parameter:\",metrics.f1_score(y_test, y_pred))\n",
    "\n",
    "# L1 penalty\n",
    "\n",
    "logreg = LogisticRegression(max_iter=20000)\n",
    "\n",
    "gs_random = GridSearchCV(estimator = logreg, param_grid = {'penalty': ['l1'], 'solver': ['saga']}, scoring = 'f1', cv= 10)\n",
    "gs_random.fit(X_train, y_train)\n",
    "logreg_best_model = gs_random.best_estimator_\n",
    "\n",
    "y_pred = logreg_best_model.predict(X_test)\n",
    "print(\"F1 Score for Logistic Regression with l1 penaltly using GridSearchCV with Default Scoring Parameter:\",metrics.f1_score(y_test, y_pred))\n",
    "\n",
    "# L2 penalty\n",
    "\n",
    "logreg = LogisticRegression(max_iter=20000)\n",
    "\n",
    "gs_random = GridSearchCV(estimator = logreg, param_grid = {'penalty': ['l2'], 'solver': ['saga']}, scoring = 'f1', cv= 10)\n",
    "gs_random.fit(X_train, y_train)\n",
    "logreg_best_model = gs_random.best_estimator_\n",
    "\n",
    "y_pred = logreg_best_model.predict(X_test)\n",
    "print(\"F1 Score for Logistic Regression with l2 penaltly using GridSearchCV with Default Scoring Parameter:\",metrics.f1_score(y_test, y_pred))\n",
    "\n",
    "# Elasticnet penalty\n",
    "\n",
    "logreg = LogisticRegression(max_iter=20000)\n",
    "\n",
    "gs_random = GridSearchCV(estimator = logreg, param_grid = {'penalty': ['elasticnet'], 'solver': ['saga'], 'l1_ratio': [0.5]}, scoring = 'f1', cv= 10)\n",
    "gs_random.fit(X_train, y_train)\n",
    "logreg_best_model = gs_random.best_estimator_\n",
    "\n",
    "y_pred = logreg_best_model.predict(X_test)\n",
    "print(\"F1 Score for Logistic Regression with elasticnet penaltly using GridSearchCV with Default Scoring Parameter:\",metrics.f1_score(y_test, y_pred))\n",
    "\n",
    "print(\"\\nWith Normalization\\n\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(ntemp, target, test_size=0.2, random_state = 42)\n",
    "\n",
    "# No penalty\n",
    "\n",
    "logreg = LogisticRegression(max_iter=20000)\n",
    "\n",
    "gs_random = GridSearchCV(estimator = logreg, param_grid = {'penalty': ['none'], 'solver': ['saga']}, scoring = 'f1', cv= 10)\n",
    "gs_random.fit(X_train, y_train)\n",
    "logreg_best_model = gs_random.best_estimator_\n",
    "\n",
    "y_pred = logreg_best_model.predict(X_test)\n",
    "print(\"F1 Score for Logistic Regression with no penaltly using GridSearchCV with Default Scoring Parameter:\",metrics.f1_score(y_test, y_pred))\n",
    "\n",
    "# L1 penalty\n",
    "\n",
    "logreg = LogisticRegression(max_iter=20000)\n",
    "\n",
    "gs_random = GridSearchCV(estimator = logreg, param_grid = {'penalty': ['l1'], 'solver': ['saga']}, scoring = 'f1', cv= 10)\n",
    "gs_random.fit(X_train, y_train)\n",
    "logreg_best_model = gs_random.best_estimator_\n",
    "\n",
    "y_pred = logreg_best_model.predict(X_test)\n",
    "print(\"F1 Score for Logistic Regression with l1 penaltly using GridSearchCV with Default Scoring Parameter:\",metrics.f1_score(y_test, y_pred))\n",
    "\n",
    "# L2 penalty\n",
    "\n",
    "logreg = LogisticRegression(max_iter=20000)\n",
    "\n",
    "gs_random = GridSearchCV(estimator = logreg, param_grid = {'penalty': ['l2'], 'solver': ['saga']}, scoring = 'f1', cv= 10)\n",
    "gs_random.fit(X_train, y_train)\n",
    "logreg_best_model = gs_random.best_estimator_\n",
    "\n",
    "y_pred = logreg_best_model.predict(X_test)\n",
    "print(\"F1 Score for Logistic Regression with l2 penaltly using GridSearchCV with Default Scoring Parameter:\",metrics.f1_score(y_test, y_pred))\n",
    "\n",
    "# Elasticnet penalty\n",
    "\n",
    "logreg = LogisticRegression(max_iter=20000)\n",
    "\n",
    "gs_random = GridSearchCV(estimator = logreg, param_grid = {'penalty': ['elasticnet'], 'solver': ['saga'], 'l1_ratio': [0.5]}, scoring = 'f1', cv= 10)\n",
    "gs_random.fit(X_train, y_train)\n",
    "logreg_best_model = gs_random.best_estimator_\n",
    "\n",
    "y_pred = logreg_best_model.predict(X_test)\n",
    "print(\"F1 Score for Logistic Regression with elasticnet penaltly using GridSearchCV with Default Scoring Parameter:\",metrics.f1_score(y_test, y_pred))\n",
    "\n",
    "print(\"\\nWith Standardization\\n\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(stemp, target, test_size=0.2, random_state = 42)\n",
    "\n",
    "# No penalty\n",
    "\n",
    "logreg = LogisticRegression(max_iter=20000)\n",
    "\n",
    "gs_random = GridSearchCV(estimator = logreg, param_grid = {'penalty': ['none'], 'solver': ['saga']}, scoring = 'f1', cv= 10)\n",
    "gs_random.fit(X_train, y_train)\n",
    "logreg_best_model = gs_random.best_estimator_\n",
    "\n",
    "y_pred = logreg_best_model.predict(X_test)\n",
    "print(\"F1 Score for Logistic Regression with no penaltly using GridSearchCV with Default Scoring Parameter:\",metrics.f1_score(y_test, y_pred))\n",
    "\n",
    "# L1 penalty\n",
    "\n",
    "logreg = LogisticRegression(max_iter=20000)\n",
    "\n",
    "gs_random = GridSearchCV(estimator = logreg, param_grid = {'penalty': ['l1'], 'solver': ['saga']}, scoring = 'f1', cv= 10)\n",
    "gs_random.fit(X_train, y_train)\n",
    "logreg_best_model = gs_random.best_estimator_\n",
    "\n",
    "y_pred = logreg_best_model.predict(X_test)\n",
    "print(\"F1 Score for Logistic Regression with l1 penaltly using GridSearchCV with Default Scoring Parameter:\",metrics.f1_score(y_test, y_pred))\n",
    "\n",
    "# L2 penalty\n",
    "\n",
    "logreg = LogisticRegression(max_iter=20000)\n",
    "\n",
    "gs_random = GridSearchCV(estimator = logreg, param_grid = {'penalty': ['l2'], 'solver': ['saga']}, scoring = 'f1', cv= 10)\n",
    "gs_random.fit(X_train, y_train)\n",
    "logreg_best_model = gs_random.best_estimator_\n",
    "\n",
    "y_pred = logreg_best_model.predict(X_test)\n",
    "print(\"F1 Score for Logistic Regression with l2 penaltly using GridSearchCV with Default Scoring Parameter:\",metrics.f1_score(y_test, y_pred))\n",
    "\n",
    "# Elasticnet penalty\n",
    "\n",
    "logreg = LogisticRegression(max_iter=20000)\n",
    "\n",
    "gs_random = GridSearchCV(estimator = logreg, param_grid = {'penalty': ['elasticnet'], 'solver': ['saga'], 'l1_ratio': [0.5]}, scoring = 'f1', cv= 10)\n",
    "gs_random.fit(X_train, y_train)\n",
    "logreg_best_model = gs_random.best_estimator_\n",
    "\n",
    "y_pred = logreg_best_model.predict(X_test)\n",
    "print(\"F1 Score for Logistic Regression with elasticnet penaltly using GridSearchCV with Default Scoring Parameter:\",metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using GridSearch to select hyperparameters for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: KNeighborsClassifier(leaf_size=10, n_neighbors=20, p=1)\n",
      "\n",
      "Best Parameters: {'algorithm': 'auto', 'leaf_size': 10, 'n_neighbors': 20, 'p': 1, 'weights': 'uniform'}\n",
      "\n",
      "F1 Score for K-Nearest Neighbors: 0.7922437673130193\n",
      "Wall time: 46.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Using GridSearch to select the best parameters for the K-Nearest Neighbors model\n",
    "\n",
    "temp = temp2\n",
    "X_train, X_test, y_train, y_test = train_test_split(temp, target, test_size=0.2, random_state = 42)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "knn_params = { \n",
    "    'n_neighbors': [2, 5, 7, 10, 12, 15, 17, 20],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'leaf_size': [10, 20, 30, 40, 50],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "\n",
    "gs_random = GridSearchCV(estimator = knn, param_grid = knn_params, scoring = 'f1', cv= 10)\n",
    "gs_random.fit(X_train, y_train)\n",
    "knn_best_model = gs_random.best_estimator_\n",
    "knn_best_params = gs_random.best_params_\n",
    "\n",
    "print (\"Best Model:\", knn_best_model)\n",
    "print (\"\\nBest Parameters:\", knn_best_params)\n",
    "\n",
    "y_pred = knn_best_model.predict(X_test)\n",
    "print(\"\\nF1 Score for K-Nearest Neighbors:\",metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: RandomForestClassifier(criterion='entropy', max_features='sqrt',\n",
      "                       n_estimators=125)\n",
      "\n",
      "Best Parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 125}\n",
      "\n",
      "F1 Score for Random Forest: 0.8089887640449438\n",
      "Wall time: 2min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Using GridSearch to select the best parameters for the Random Forests model\n",
    "\n",
    "temp = temp2\n",
    "X_train, X_test, y_train, y_test = train_test_split(temp, target, test_size=0.2, random_state = 42)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf_params = { \n",
    "    'n_estimators': [10, 25, 50, 75, 100, 125, 150, 175, 200],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "}\n",
    "\n",
    "gs_random = GridSearchCV(estimator = rf, param_grid = rf_params, scoring = 'f1', cv= 10)\n",
    "gs_random.fit(X_train, y_train)\n",
    "rf_best_model = gs_random.best_estimator_\n",
    "rf_best_params = gs_random.best_params_\n",
    "\n",
    "print (\"Best Model:\", rf_best_model)\n",
    "print (\"\\nBest Parameters:\", rf_best_params)\n",
    "\n",
    "y_pred = rf_best_model.predict(X_test)\n",
    "print(\"\\nF1 Score for Random Forest:\",metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: LogisticRegression(max_iter=20000, solver='newton-cg', tol=0.1)\n",
      "\n",
      "Best Parameters: {'C': 1.0, 'solver': 'newton-cg', 'tol': 0.1}\n",
      "\n",
      "F1 Score for Logistic Regression: 0.7978142076502731\n",
      "Wall time: 1min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Using GridSearch to select the best parameters for the Logistic Regression model\n",
    "\n",
    "temp = temp2\n",
    "X_train, X_test, y_train, y_test = train_test_split(temp, target, test_size=0.2, random_state = 42)\n",
    "\n",
    "logreg = LogisticRegression(max_iter = 20000)\n",
    "\n",
    "logreg_params = {\n",
    "    'C': [0.1, 0.3, 0.5, 0.7, 1.0],\n",
    "    'tol': [1e-1, 1e-2, 1e-3, 1e-4],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "}\n",
    "\n",
    "gs_random = GridSearchCV(estimator = logreg, param_grid = logreg_params, scoring = 'f1', cv= 10)\n",
    "gs_random.fit(X_train, y_train)\n",
    "logreg_best_model = gs_random.best_estimator_\n",
    "logreg_best_params = gs_random.best_params_\n",
    "\n",
    "print (\"Best Model:\", logreg_best_model)\n",
    "print (\"\\nBest Parameters:\", logreg_best_params)\n",
    "\n",
    "y_pred = logreg_best_model.predict(X_test)\n",
    "print(\"\\nF1 Score for Logistic Regression:\",metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: MLPClassifier(activation='logistic', alpha=0.01, early_stopping=True,\n",
      "              max_iter=20000, tol=0.1)\n",
      "\n",
      "Best Parameters: {'activation': 'logistic', 'alpha': 0.01, 'early_stopping': True, 'tol': 0.1}\n",
      "\n",
      "F1 Score for Artificial Neural Network: 0.775623268698061\n",
      "Wall time: 50.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Using GridSearch to select the best parameters for the Artificial Neural Networks model\n",
    "\n",
    "temp = temp2\n",
    "X_train, X_test, y_train, y_test = train_test_split(temp, target, test_size=0.2, random_state = 42)\n",
    "\n",
    "mlpc = MLPClassifier(max_iter=20000)\n",
    "\n",
    "mlpc_params = { \n",
    "    'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "    'alpha': [1e-1, 1e-2, 1e-3, 1e-4],\n",
    "    'tol': [1e-1, 1e-2, 1e-3, 1e-4],\n",
    "    'early_stopping': [True]\n",
    "}\n",
    "\n",
    "gs_random = GridSearchCV(estimator = mlpc, param_grid = mlpc_params, scoring = 'f1', cv= 10)\n",
    "gs_random.fit(X_train, y_train)\n",
    "mlpc_best_model = gs_random.best_estimator_\n",
    "mlpc_best_params = gs_random.best_params_\n",
    "\n",
    "print (\"Best Model:\", mlpc_best_model)\n",
    "print (\"\\nBest Parameters:\", mlpc_best_params)\n",
    "\n",
    "y_pred = mlpc_best_model.predict(X_test)\n",
    "print(\"\\nF1 Score for Artificial Neural Network:\",metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Grid Search to select hyperparameters after data has been Normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: KNeighborsClassifier(leaf_size=10, n_neighbors=17)\n",
      "\n",
      "Best Parameters: {'algorithm': 'auto', 'leaf_size': 10, 'n_neighbors': 17, 'p': 2, 'weights': 'uniform'}\n",
      "\n",
      "F1 Score for K-Nearest Neighbors: 0.7925531914893617\n",
      "Wall time: 31.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Using GridSearch to select the best parameters for the K-Nearest Neighbors model\n",
    "# The data here has been normalized\n",
    "\n",
    "temp = temp2\n",
    "ntemp = preprocessing.normalize(temp)\n",
    "X_train, X_test, y_train, y_test = train_test_split(ntemp, target, test_size=0.2, random_state = 42)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "knn_params = { \n",
    "    'n_neighbors': [2, 5, 7, 10, 12, 15, 17, 20],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'leaf_size': [10, 20, 30, 40, 50],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "\n",
    "gs_random = GridSearchCV(estimator = knn, param_grid = knn_params, scoring = 'f1', cv= 10)\n",
    "gs_random.fit(X_train, y_train)\n",
    "knn_best_model = gs_random.best_estimator_\n",
    "knn_best_params = gs_random.best_params_\n",
    "\n",
    "print (\"Best Model:\", knn_best_model)\n",
    "print (\"\\nBest Parameters:\", knn_best_params)\n",
    "\n",
    "y_pred = knn_best_model.predict(X_test)\n",
    "print(\"\\nF1 Score for K-Nearest Neighbors:\",metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: RandomForestClassifier(criterion='entropy', max_features='log2',\n",
      "                       n_estimators=50)\n",
      "\n",
      "Best Parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 50}\n",
      "\n",
      "F1 Score for Random Forest: 0.785515320334262\n",
      "Wall time: 2min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Using GridSearch to select the best parameters for the Random Forests model\n",
    "# The data here has been normalized\n",
    "\n",
    "temp = temp2\n",
    "ntemp = preprocessing.normalize(temp)\n",
    "X_train, X_test, y_train, y_test = train_test_split(ntemp, target, test_size=0.2, random_state = 42)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf_params = { \n",
    "    'n_estimators': [10, 25, 50, 75, 100, 125, 150, 175, 200],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "}\n",
    "\n",
    "gs_random = GridSearchCV(estimator = rf, param_grid = rf_params, scoring = 'f1', cv= 10)\n",
    "gs_random.fit(X_train, y_train)\n",
    "rf_best_model = gs_random.best_estimator_\n",
    "rf_best_params = gs_random.best_params_\n",
    "\n",
    "print (\"Best Model:\", rf_best_model)\n",
    "print (\"\\nBest Parameters:\", rf_best_params)\n",
    "\n",
    "y_pred = rf_best_model.predict(X_test)\n",
    "print(\"\\nF1 Score for Random Forest:\",metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: LogisticRegression(C=0.5, max_iter=20000, solver='sag', tol=0.001)\n",
      "\n",
      "Best Parameters: {'C': 0.5, 'solver': 'sag', 'tol': 0.001}\n",
      "\n",
      "F1 Score for Logistic Regression: 0.7821782178217822\n",
      "Wall time: 4.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Using GridSearch to select the best parameters for the Logistic Regression model\n",
    "# The data here has been normalized\n",
    "\n",
    "temp = temp2\n",
    "ntemp = preprocessing.normalize(temp)\n",
    "X_train, X_test, y_train, y_test = train_test_split(ntemp, target, test_size=0.2, random_state = 42)\n",
    "\n",
    "logreg = LogisticRegression(max_iter=20000)\n",
    "\n",
    "logreg_params = {\n",
    "    'C': [0.1, 0.3, 0.5, 0.7, 1.0],\n",
    "    'tol': [1e-1, 1e-2, 1e-3, 1e-4],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "}\n",
    "\n",
    "gs_random = GridSearchCV(estimator = logreg, param_grid = logreg_params, scoring = 'f1', cv= 10)\n",
    "gs_random.fit(X_train, y_train)\n",
    "logreg_best_model = gs_random.best_estimator_\n",
    "logreg_best_params = gs_random.best_params_\n",
    "\n",
    "print (\"Best Model:\", logreg_best_model)\n",
    "print (\"\\nBest Parameters:\", logreg_best_params)\n",
    "\n",
    "y_pred = logreg_best_model.predict(X_test)\n",
    "print(\"\\nF1 Score for Logistic Regression:\",metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: MLPClassifier(activation='identity', early_stopping=True, max_iter=20000,\n",
      "              tol=0.1)\n",
      "\n",
      "Best Parameters: {'activation': 'identity', 'alpha': 0.0001, 'early_stopping': True, 'tol': 0.1}\n",
      "\n",
      "F1 Score for Artificial Neural Network: 0.7734553775743707\n",
      "Wall time: 28.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Using GridSearch to select the best parameters for the Artificial Neural Networks model\n",
    "# The data here has been normalized\n",
    "\n",
    "temp = temp2\n",
    "ntemp = preprocessing.normalize(temp)\n",
    "X_train, X_test, y_train, y_test = train_test_split(ntemp, target, test_size=0.2, random_state = 42)\n",
    "\n",
    "mlpc = MLPClassifier(max_iter=20000)\n",
    "\n",
    "mlpc_params = { \n",
    "    'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "    'alpha': [1e-1, 1e-2, 1e-3, 1e-4],\n",
    "    'tol': [1e-1, 1e-2, 1e-3, 1e-4],\n",
    "    'early_stopping': [True]\n",
    "}\n",
    "\n",
    "gs_random = GridSearchCV(estimator = mlpc, param_grid = mlpc_params, scoring = 'f1', cv= 10)\n",
    "gs_random.fit(X_train, y_train)\n",
    "mlpc_best_model = gs_random.best_estimator_\n",
    "mlpc_best_params = gs_random.best_params_\n",
    "\n",
    "print (\"Best Model:\", mlpc_best_model)\n",
    "print (\"\\nBest Parameters:\", mlpc_best_params)\n",
    "\n",
    "y_pred = mlpc_best_model.predict(X_test)\n",
    "print(\"\\nF1 Score for Artificial Neural Network:\",metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Grid Search to select hyperparameters after data has been Standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: KNeighborsClassifier(leaf_size=10, n_neighbors=15, p=1)\n",
      "\n",
      "Best Parameters: {'algorithm': 'auto', 'leaf_size': 10, 'n_neighbors': 15, 'p': 1, 'weights': 'uniform'}\n",
      "\n",
      "F1 Score for K-Nearest Neighbors: 0.7933884297520661\n",
      "Wall time: 35.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Using GridSearch to select the best parameters for the K-Nearest Neighbors model\n",
    "# The data here has been standardized\n",
    "\n",
    "temp = temp2\n",
    "stemp = preprocessing.scale(temp)\n",
    "X_train, X_test, y_train, y_test = train_test_split(stemp, target, test_size=0.2, random_state = 42)\n",
    "\n",
    "#Create KNN Classifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "knn_params = { \n",
    "    'n_neighbors': [2, 5, 7, 10, 12, 15, 17, 20],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'leaf_size': [10, 20, 30, 40, 50],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "\n",
    "gs_random = GridSearchCV(estimator = knn, param_grid = knn_params, scoring = 'f1', cv= 10)\n",
    "gs_random.fit(X_train, y_train)\n",
    "knn_best_model = gs_random.best_estimator_\n",
    "knn_best_params = gs_random.best_params_\n",
    "\n",
    "print (\"Best Model:\", knn_best_model)\n",
    "print (\"\\nBest Parameters:\", knn_best_params)\n",
    "\n",
    "y_pred = knn_best_model.predict(X_test)\n",
    "print(\"\\nF1 Score for K-Nearest Neighbors:\",metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: RandomForestClassifier(criterion='entropy', max_features='sqrt',\n",
      "                       n_estimators=75)\n",
      "\n",
      "Best Parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 75}\n",
      "\n",
      "F1 Score for Random Forest: 0.8044077134986226\n",
      "Wall time: 2min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Using GridSearch to select the best parameters for the Random Forests model\n",
    "# The data here has been standardized\n",
    "\n",
    "temp = temp2\n",
    "stemp = preprocessing.scale(temp)\n",
    "X_train, X_test, y_train, y_test = train_test_split(stemp, target, test_size=0.2, random_state = 42)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf_params = { \n",
    "    'n_estimators': [10, 25, 50, 75, 100, 125, 150, 175, 200],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "}\n",
    "\n",
    "gs_random = GridSearchCV(estimator = rf, param_grid = rf_params, scoring = 'f1', cv= 10)\n",
    "gs_random.fit(X_train, y_train)\n",
    "rf_best_model = gs_random.best_estimator_\n",
    "rf_best_params = gs_random.best_params_\n",
    "\n",
    "print (\"Best Model:\", rf_best_model)\n",
    "print (\"\\nBest Parameters:\", rf_best_params)\n",
    "\n",
    "y_pred = rf_best_model.predict(X_test)\n",
    "print(\"\\nF1 Score for Random Forest:\",metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: LogisticRegression(C=0.1, max_iter=20000, solver='saga', tol=0.01)\n",
      "\n",
      "Best Parameters: {'C': 0.1, 'solver': 'saga', 'tol': 0.01}\n",
      "\n",
      "F1 Score for Logistic Regression: 0.7988826815642458\n",
      "Wall time: 4.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Using GridSearch to select the best parameters for the Logistic Regression model\n",
    "# The data here has been standardized\n",
    "\n",
    "temp = temp2\n",
    "stemp = preprocessing.scale(temp)\n",
    "X_train, X_test, y_train, y_test = train_test_split(stemp, target, test_size=0.2, random_state = 42)\n",
    "\n",
    "logreg = LogisticRegression(max_iter=20000)\n",
    "\n",
    "logreg_params = {\n",
    "    'C': [0.1, 0.3, 0.5, 0.7, 1.0],\n",
    "    'tol': [1e-1, 1e-2, 1e-3, 1e-4],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "}\n",
    "\n",
    "gs_random = GridSearchCV(estimator = logreg, param_grid = logreg_params, scoring = 'f1', cv= 10)\n",
    "gs_random.fit(X_train, y_train)\n",
    "logreg_best_model = gs_random.best_estimator_\n",
    "logreg_best_params = gs_random.best_params_\n",
    "\n",
    "print (\"Best Model:\", logreg_best_model)\n",
    "print (\"\\nBest Parameters:\", logreg_best_params)\n",
    "\n",
    "y_pred = logreg_best_model.predict(X_test)\n",
    "print(\"\\nF1 Score for Logistic Regression:\",metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: MLPClassifier(activation='logistic', early_stopping=True, max_iter=20000)\n",
      "\n",
      "Best Parameters: {'activation': 'logistic', 'alpha': 0.0001, 'early_stopping': True, 'tol': 0.0001}\n",
      "\n",
      "F1 Score for Artificial Neural Network: 0.7862407862407863\n",
      "Wall time: 46.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Using GridSearch to select the best parameters for the Artificial Neural Networks model\n",
    "# The data here has been standardized\n",
    "\n",
    "temp = temp2\n",
    "stemp = preprocessing.scale(temp)\n",
    "X_train, X_test, y_train, y_test = train_test_split(stemp, target, test_size=0.2, random_state = 42)\n",
    "\n",
    "mlpc = MLPClassifier(max_iter=20000)\n",
    "\n",
    "mlpc_params = { \n",
    "    'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "    'alpha': [1e-1, 1e-2, 1e-3, 1e-4],\n",
    "    'tol': [1e-1, 1e-2, 1e-3, 1e-4],\n",
    "    'early_stopping': [True]\n",
    "}\n",
    "\n",
    "gs_random = GridSearchCV(estimator = mlpc, param_grid = mlpc_params, scoring = 'f1', cv= 10)\n",
    "gs_random.fit(X_train, y_train)\n",
    "mlpc_best_model = gs_random.best_estimator_\n",
    "mlpc_best_params = gs_random.best_params_\n",
    "\n",
    "print (\"Best Model:\", mlpc_best_model)\n",
    "print (\"\\nBest Parameters:\", mlpc_best_params)\n",
    "\n",
    "y_pred = mlpc_best_model.predict(X_test)\n",
    "print(\"\\nF1 Score for Artificial Neural Network:\",metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
